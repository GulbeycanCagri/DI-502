# DI-502
DI 502 Project Repository — RAG-based Chatbot for Answering Finance Questions

## Features

* **FastAPI Backend**: A lightweight web framework to serve the application and handle API requests.
* **Llama 3 8B Integration**: Uses a 4-bit quantized version of `meta-llama/Meta-Llama-3-8B-Instruct` for efficient text generation.
* **Retrieval-Augmented Generation (RAG)**: Leverages `llama-index` to answer questions based on the content of user-uploaded documents.
* **Simple HTML/JS Frontend**: A clean, single-page interface for interacting with the chatbot.
* **Robust Testing**: Includes a `pytest` suite with mocking capabilities to test API endpoints without loading heavy GPU models.

---
## Project Structure

The repository is organized into a simple structure for a self-contained web application.

```text
.
├── backend/
│   ├── src/            # Backend source code (rag_service.py, etc.)
│   ├── uploads/        # Default location for file uploads
│   ├── main.py         # FastAPI application entrypoint
│   └── requirements.txt  # Backend Python dependencies
├── tests/              # Test suite
│   └── test_main.py    # API and Integration tests
├── data/               # Persistent data (e.g., vector stores)
├── frontend/           # Frontend application (React, Vue, etc.)
├── templates/          # (Optional: e.g., for Jinja2 templates if used)
├── .dockerignore
├── .gitignore
├── backend.Dockerfile    # Docker build instructions for the backend
├── docker-compose.yaml   # Defines all services (backend, frontend, nginx)
├── frontend.Dockerfile   # Docker build instructions for the frontend
├── nginx.conf          # Nginx configuration for reverse proxy
└── README.md
```
## Getting Started

Follow these instructions to get the project running on your local machine.

### Prerequisites

You'll need the following software installed:
* [Python 3.10+](https://www.python.org/downloads/)
* [Git](https://git-scm.com/)
* An NVIDIA GPU is highly recommended for running the model (production mode).

### Installation

1.  **Clone the repository:**
    ```bash
    git clone [https://github.com/GulbeycanCagri/DI-502.git](https://github.com/GulbeycanCagri/DI-502.git)
    cd DI-502
    ```

2.  **Create and activate a Python virtual environment:**
    ```bash
    python3 -m venv .venv
    source .venv/bin/activate
    # On Windows, use: .venv\Scripts\activate
    ```

3.  **Install dependencies:**
    ```bash
    # Install backend requirements
    pip install -r backend/requirements.txt
    
    # Install testing requirements
    pip install pytest httpx
    ```
    *Note: This step may take some time as it downloads several large libraries, including PyTorch.*

---
## Usage

1.  **Activate the virtual environment (if not already active):**
    ```bash
    source .venv/bin/activate
    ```

2.  **Run the FastAPI application:**
    Use `uvicorn` to start the server. Run this command from the project root:
    ```bash
    uvicorn backend.main:app --reload
    ```
    The application will start, and the model will be loaded into memory. This may take a few moments.

3.  **Access the chatbot:**
    Open your web browser and navigate to `http://127.0.0.1:8000`.

    You can now upload a document (`.pdf`, `.txt`, `.md`), ask a question about it, and receive an answer generated by the Llama 3 model.

---
## Testing

This project uses `pytest` for testing. The test suite is designed to be **lightweight and fast**.

* **Mocking:** The heavy AI models (Llama 3, Transformers) are **mocked** during testing. This prevents GPU memory errors and allows tests to run instantly on any machine (even without a GPU).
* **Coverage:** Tests cover API endpoints, file uploads, error handling (422/400 codes), and integration logic.

To run the tests, execute the following command from the **project root directory**:

```bash
pytest
```
---
---
## API Endpoints

The FastAPI application provides the following endpoints:

| Method | Endpoint | Description |
| :--- | :--- | :--- |
| `GET` | `/` | Serves the main chat page (`index.html`) or API root message. |
| `POST` | `/chat` | Main RAG endpoint. Accepts form data: `question` (text), `use_online_research` (bool), and optional `document` (file upload). |
| `GET` | `/docs` | Automatic interactive API documentation (Swagger UI). |
| `GET` | `/redoc` | Alternative API documentation (ReDoc). ||

---
