# DI-502
DI 502 Project Repository — RAG-based Chatbot for Answering Finance Questions

## Features

*   **Flask Backend**: A lightweight web framework to serve the application and handle API requests.
*   **Llama 3 8B Integration**: Uses a 4-bit quantized version of `meta-llama/Meta-Llama-3-8B-Instruct` for efficient text generation.
*   **Retrieval-Augmented Generation (RAG)**: Leverages `llama-index` to answer questions based on the content of user-uploaded documents.
*   **Simple HTML/JS Frontend**: A clean, single-page interface for interacting with the chatbot.

---
## Project Structure

The repository is organized into a simple structure for a self-contained web application.

```
.
├── app.py              # Flask backend server
├── requirements.txt    # Python dependencies
├── src/
│   └── rag_service.py  # RAG and model logic
├── templates/
│   └── index.html      # Frontend HTML and JavaScript
└── README.md
```

---
## Getting Started

Follow these instructions to get the project running on your local machine.

### Prerequisites

You'll need the following software installed:
*   [Python 3.10+](https://www.python.org/downloads/)
*   [Git](https://git-scm.com/)
*   An NVIDIA GPU is highly recommended for running the model.

### Installation

1.  **Clone the repository:**
    ```bash
    git clone <your-repo-url>
    cd DI-502
    ```

2.  **Create and activate a Python virtual environment:**
    ```bash
    python3 -m venv .venv
    source .venv/bin/activate
    # On Windows, use: .venv\Scripts\activate
    ```

3.  **Install dependencies:**
    ```bash
    pip install -r requirements.txt
    ```
    *Note: This step may take some time as it downloads several large libraries, including PyTorch.*

---
## Usage

1.  **Activate the virtual environment (if not already active):**
    ```bash
    source .venv/bin/activate
    ```

2.  **Run the Flask application:**
    ```bash
    python app.py
    ```
    The application will start, and the model will be loaded into memory. This may take a few moments.

3.  **Access the chatbot:**
    Open your web browser and navigate to `http://127.0.0.1:5000`.

    You can now upload a document (`.pdf`, `.txt`, `.md`), ask a question about it, and receive an answer generated by the Llama 3 model.

---
## API Endpoints

The Flask application provides the following endpoints:

| Method | Endpoint | Description |
| :--- | :--- | :--- |
| `GET` | `/` | Serves the main chat page (`index.html`). |
| `POST` | `/api/chat` | Receives a question and a document, and returns a RAG-generated answer. |

---
